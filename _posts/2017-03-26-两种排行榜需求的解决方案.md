---
layout: post
title: 两种排行榜需求的解决方案
categories: 技术总结
author: whiteesky
date: 2017-03-26 20:28:08
tags:
  - Redis
  - Java
header-img: img/article/2.jpg
copyright: true
---
针对排行榜需求，我们一般都会采用Redis等缓存去存储，MySQL不足以支撑高并发的查询。而针对不同的需求，我们也应该按照实际情况进行分析，没有最好的方法，只有更合适的方法。

下面是针对一种阅读APP提出的两种排行需求。

第一种需求
-----

统计每天用户的消费金额，每天结束时根据消费金额的排行对用户进行奖励。消费额相同时，先达到该额度的用户排名靠前。通过分析需求：
1. 排行榜实时性要求低，可10分钟更新一次。
2. 每天会进行消费的用户人数不多，在几万个左右。
3. 但是每个用户的订单数量会比较多（用户阅读时每购买一章就会生成一个订单，一般用户会连续看N多章）。

在Redis中，刚好有一个SortedSet结构，每个元素都有一个member值和score值，能自动按照score进行比较对各元素进行排序。

我们利用一个定时任务，每隔十分钟从DB统计今天用户消费的数据，利用ZINCRBY的方式写入到Redis的SortedSet当中，直接供接口读取。其中注意几点：

 1. 由于每天订单总量还是很大，所以我们只在每天第一次计算时，以时间为条件查询DB当前天的数据。查询完成后，将最后一个订单id写入Redis。之后每次再计算时，只查询id大于Redis key的新增订单即可。

 2. Redis的SortedSet中，由于score值是double类型的，根据需求所述，我们把消费额存在整数部分，把时间戳存在小数部分。又因为整数部分相同时，小数部分大的反而应该被认为排名靠后，所以我们把小数部分存为一个足够大的固定值减去时间戳。这样保存之后，就可以利用SortedSet自动进行排序了。当然，这种方法要保证当前业务的数据不会超出double的精度。

 3. 每次读出新增订单之后，需要遍历写入Redis，但是当时效率很低。后来发现Redis可以使用一种pipeline管道的方式，将数据批量写入，效率快了非常多。如下：

```java
Pipeline p = jedis.pipelined();
for (TestOrder order : testList) {
    p.zincrby(key, order.getPirce(), order.getCustomerId());
}
p.sync();
```

第二种需求
-----

统计用户每周阅读的分钟数，每周结束时给阅读时长靠前的用户发奖励。通过分析需求：

 1. 用户量极大，每周只要打开过阅读器的用户都会统计到。
 2. 排行榜分数是固定的，就是每周的分钟数，最大只有 24 &times; 60 &times; 7 = 10080。

由于用户量极大，每次用户分数更新时在集合中排序效率就有点低了。不过关键的是，排行榜的分数值只有固定的1-10080。

针对此种情况，只需要做对应分数个数的桶（List）放在Cache里，每个桶记录当前这个分数有多少个人就可以了。每当用户分数更改，就把原来分数的桶减1，新的桶加1。
例如，用户A原来为5000分钟，阅读一小时之后为5060分钟，那么就将下标为5000的桶的人数减1，下标为5060的桶加1。

当每个用户查询自己的排名时，只要把比用户当前分数靠前的桶的数值累加，就能够查到用户的名次。时间复杂度为O(n)。比起百万级的大量用户直接排名，桶个数的数量级扫一遍时间就很短了。
例如，用户A查询自己的排名，则遍历5061-10080的桶，累加所有桶的人数，即为比用户A排名高的用户。

而针对详细的榜单，一般也就会显示几百个用户。所以针对这个数量级直接用排序算法做也就很快了。
